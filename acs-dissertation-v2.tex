%% 
%% ACS project dissertation template. 
%% 
%% Currently designed for printing two-sided, but if you prefer to 
%% print single-sided just remove ",twoside,openright" from the 
%% \documentclass[] line below. 
%%
%%
%%   SMH, May 2010. 


\documentclass[a4paper,12pt,twoside,openright]{report}


%%
%% EDIT THE BELOW TO CUSTOMIZE
%%

\def\authorname{Francisco A.\ Vargas\xspace}
\def\authorcollege{Girton College\xspace}
\def\authoremail{fav25@cam.ac.uk}
\def\dissertationtitle{Machine Learning Approaches for The Empirical Schrödinger Bridge Problem}
\def\wordcount{200}


%\usepackage[dvips]{epsfig,graphics} 
\usepackage{epsfig,graphicx,verbatim,parskip,tabularx,setspace,xspace}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{amsfonts}

\usepackage{natbib}

\usepackage{tikz}
\usepackage{bayesnet}
\usepackage[linesnumbered, ruled]{algorithm2e}


\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amsthm}




\input{math_commands.tex}


\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{observation}[theorem]{Observation}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

%% START OF DOCUMENT
\begin{document}


%% FRONTMATTER (TITLE PAGE, DECLARATION, ABSTRACT, ETC) 
\pagestyle{empty}
\singlespacing
\input{titlepage}
\onehalfspacing
\input{declaration}
\singlespacing
\input{abstract}

\pagenumbering{roman}
\setcounter{page}{0}
\pagestyle{plain}
\tableofcontents
\listoffigures
\listoftables

\onehalfspacing

%% START OF MAIN TEXT 

 \chapter{Introduction}
 \pagenumbering{arabic} 
 
 The motion of small particles in a fluid and the value of financial instruments as a function of time have an interesting intersection. These two processes have a large number of underlying factors (i.e. physical forces) that impact their trajectories and constantly change as a function of time. This dramatic and constant stream of varying forces cause the trajectory of these systems to seem random and make it unfeasible to model with classical physics. 
 
 What we today call Brownian motion is a random process and one of the simplest physical models that is used to describe the motion of small particles in a fluid. Some of the earliest mathematical formulations of this process date back to \cite{einstein1905motion}, where the diffusion-based formulation of Brownian motion was used to describe the motion of pollen particles in a fluid.
 
 As one then may naturally and accurately conjecture, many day-to-day processes have an element of Brownian motion within them, and thus Brownian motion has become a substantial mathematical tool when describing the motion of volatile temporal processes.
 
 A class of Brownian-motion-driven processes that are of particular interest to many areas of applied science are the drift-augmented Brownian motions. In simple terms, this family of processes can be split into two components: one being a Brownian-motion-driven term and the other being a drift which provides a directional drive to the system, much like a driving force.  A particular example process that is popular in the Machine Learning and Computational Neuroscience communities is the Ornstein–Uhlenbeck (OU) process. The OU-process is used to model particles undergoing Brownian motion that are subject to friction, here the drift term represents the friction. Another interesting remark is that the discrete-time analogue of the OU-process is the auto-regressive process of order $1$ -- $\text{AR}(1)$, which has multiple uses in time-series analysis and signal processing. Whilst in practice these processes are discretised, their continuous time formulation remain useful objects for the study of their theoretical properties.
 
 This project is concerned with a specific event regarding Brownian-motion-driven processes proposed by Schrödinger in \citep{schrodinger1931uber, schrodinger1932theorie} . The event proposes a group of particles undergoing Brownian motion in $\R^d$, where we observe their position distributions $\pi_0(x)$ at time $0$, and then $\pi_1(y)$ at time $1$. Then, consider the case where $\pi_1(y)$ differs significantly from the predicted distribution by Brownian motion, that is
 \begin{align*}
     \pi_1(y) \neq \int p(x, 0, y , 1) \pi_1(x) dx,
 \end{align*}
 where $p(x, 0, y , 1) = p(y_1| x_0)$ represents the transition density under the Brownian motion, that is, the probability of transitioning from $x$ at time $0$ to $y$ at time $1$. We can model this event as the particles at time $0$ were transported to time $1$ in an unlikely manner (a rare event). Out of the many unlikely ways in which this event could have happened, the Schrödinger bridge answers the question of which one is the most likely. We will see down the line that this question boils down to finding a drift-augmented Brownian motion that satisfies the observed distributions and is as close to Brownian motion as possible in a KL-divergence sense.
 
 Rephrasing this in a more machine learning setting , the Schrödinger bridge is concerned with finding the most likely stochastic process that evolves a distribution $\pi_0(x)$ to another distribution $\pi_1(y)$, and is in line with a pre-specified Brownian motion prior.
 
 From an application viewpoint, the Schrödinger bridge provides us with a well-grounded mechanism for mapping between two distributions, and when those distributions are only available through samples, we effectively have a classical, unsupervised domain-adaptation problem, as illustrated in Figure \ref{fig:intuitive_bridge}. Furthermore, the Schrödinger bridge also provides us with the probability of this stochastic evolution, thus allowing us to compare two data sets/distributions which can be useful for hypothesis testing and semantic similarly.
 
 In this project will be exploring machine-learning- (neural-) based approaches to estimate the Schrödinger bridge between two distributions that are available through samples.
\begin{figure}
    \centering
    \includegraphics[scale=0.7]{images/charicaturistic_bridge.PNG}
    \caption{Intuitive Illustration of the Schrödinger Bridge}
    \label{fig:intuitive_bridge}
\end{figure}

 
\chapter{Mathematical Preliminaries}

\setcounter{page}{1}

The goal of this chapter is to introduce mathematical notation, concepts and lemmas that we will make use of throughout this study. Whilst many of these lemmas seem to be omitted as steps or taken for granted in the stochastic process literature, we found that some of them were not directly accessible when searched for and not taught in graduate-level measure and probability theory courses. Therefore, it will be useful for the community to restate and re-derive some of these results, in order to make the theory behind Schrödinger Bridges more accessible to the computational sciences.
\section{Probability Space Formalism}

For many of the technical derivations in the methodology we will study, a basic notion of measure and integration is required, thus we will refresh concepts such as $\sigalg$, probability measures,  measurable functions and the Lebesgue–Stieltjes integral, without going into unnecessary technical detail.

\begin{definition} \label{def:prob_space}
A probability space is defined as a 3-element tuple $\probspace$, where:
\begin{itemize}
    \item $\Omega$ is the sample space, i.e. the set of possible outcomes. For example, for a coin toss $\Omega=\{\text{Head}, \text{Tails}\}$. 
    \item The $\sigalg$ $\mathcal{F} \subseteq 2^{\Omega}$ which represents the set of events we may want to consider. Continuing the coin toss example, we may have $\Omega=\{\emptyset, \text{Head}, \text{Tails},\{\text{Head}, \text{Tails}\}\}$.
    \item A probability measure $\P:\calF \rightarrow [0,1]$, which is a function which assigns a number in $[0,1]$ to any event (set) in the $\sigalg$ $\calF$. The function $\P$ has the following requirements:
    \begin{itemize}
        \item $\sigma$-additive (also called countable additive), which means that if  $\bigcup_{i=0}^\infty  A_i\in \calF$ then $\P\left(\bigcup_{i=0}^\infty A_i\right) =\sum_{i=0}^\infty \P(A_i) $.
        \item $\P(\Omega)=1$, which we can read as the sample space summing up to (integrating) to 1.  Without this condition $\P$ would be a regular measure ($\sigma$-additive).
    \end{itemize}
\end{itemize}
\end{definition}
One thing to note from the above definition is that we want to be able to measure (assign a value/probability to a set) to each set in $\calF$, and this is not always possible. In other words, one can construct sets that cannot be measured (or can only be measured by the trivial measure $\callambda(A) = 0$, which is not a probability measure). Thus, we require $\calF$ to only contain measurable sets and this is what a $\sigalg$ guarantees:
\begin{definition}\label{def:sigma_algebra}
A $\sigalg$ $\calF \subseteq 2^{\Omega}$ is a collection of sets satisfying the property:
\begin{itemize}
    \item $\calF$ contains $\Omega$: $\Omega \in \calF$.
    \item $\calF$ is closed under complements: if $A\in\calF$, then $\Omega \setminus A \in \calF$.
    \item $\calF$ is closed under countable union:  if $A_i \in \calF$ then $\bigcup_i A_i \in \calF$.
\end{itemize}
\end{definition}

\begin{definition}\label{def:random_variable}
For a probability space $\probspace$, real-valued random variable (vector) $\rvx(\omega)$ is a function $\rvx :\Omega \rightarrow \R^d$, with the requirement that $\rvx(\omega)$ is a measurable function, meaning that the pre-image of $\rvx(\omega)$  lies within the $\sigalg$ $\calF$:
\begin{align*}
    \rvx^{-1}(B)= \{\omega : \rvx(\omega) \in B \} \in \calF .
\end{align*}
\end{definition}
Effectively, the above formalism of the random variable allows us to assign a numerical representation to outcomes in $\Omega$. The clear advantage is that now we can ask questions, such as what the probability that $\rvx$ is contained within a set $B \subseteq \R^d$ is:
\begin{align*}
     \text{P}(\rvx(\omega) \in B) = \P( \{\omega : \rvx(\omega) \in B \} ),
\end{align*}
 and if we consider the more familiar 1D example, we recover the cumulative distribution function (CDF):
 \begin{align*}
     \text{P}(\rx(\omega) \leq r) = \P( \{\omega : \rx(\omega) \leq r \} ).
 \end{align*}
 The random-variable formalism provides us with a more clear connection between the probability measure $\P$ and the more familiar CDF. For simplicity in some cases, we may drop the argument $\omega$ from the random variable notation (i.e $\rvx \sim \mathcal{N}(\bm{0}, \mathbb{I})$). 

\subsection{Lebesgue–Stieltjes Integral}
Here we will attempt a pragmatic introduction to the Lebesgue–Stieltjes integral, in the context of a probability space. For a more technical introduction, we point the reader to advanced probability theory or measure and integration courses.
\begin{definition}\label{def:lebesgue}
For a probability measure space $\probspace$ and a measurable function $f: \Omega \rightarrow \R $, and $A \in \calF$ the Lebesgue–Stieltjes integral
\begin{align}
    \int_{A} f(\vx) d\P(\vx)
\end{align}
is the Lebesgue integral with respect to the probability measure $\P$.
\end{definition}
Whilst we have not yet introduced a precise definition for the Lebesgue integral, we will now illustrate some of its properties that give us a grasp of this seemingly new notation:
Expectations in our probability space can be written as
\begin{align}
     \E_{\P}[f(\rvx)] = \int_{\Omega} f(\vx) d\P(\vx).
\end{align}
Let $\ind(\rvx \in A)$ be the indicator function for set $A$, then
\begin{align}
    \E_{\P}[\ind(\rvx \in A)] = \int_{\Omega} \ind(\rvx \in A) d\P(\vx) = \int_{A} d\P(\vx) = \P(A).
\end{align}
The above result is a useful example, since it shows us how the distribution (probability measure) is defined in terms of the integral. This is effectively  the definition of a cumulative density function.
When our distribution $\P$ admits a probability density function $p(\vx)$, we have the following:
\begin{align}
    \int_{\Omega} f(\vx) d\P(\vx) = \int_{\Omega} f(\vx)p(\vx) d\callambda(\vx),
\end{align}
where $\callambda$ is the Lesbesgue measure and we can just think of it as the characteristic measure for $\R^d$. For many purposes we can just interpret $\int_{\Omega} f(\vx)p(\vx) d\callambda(\vx)$ as the regular Reimann integral and in many cases authors \citep{williams2006gaussian} use $\int_{\Omega} f(\vx)p(\vx) d\vx$ notationally when the integral is with respect to the Lebesgue measure.

An important take away is that whilst connecting the Lebesgue integral to the standard Riemann integral, in the case where the PDF of a distribution $\P$ is available, gives us a useful conceptual connection, it is not always something that can be done. As we will soon see, many distributions and random processes do not admit a PDF. In order to be able to compute expectations with respect to these processes, we must adopt the Lebesgue-Stieltjes integral, which is well-defined in these settings in which the standard Riemann integral is not.
\section{Stochastic Process Formalism}
Informally a stochastic process is a time dependant random variable $\rvx(t)$, that is its a random variable whose distribution at any point in time $P_t(\rvx(t) < r)$  is itself a function of time.
\begin{definition}\label{def:stochproc}
Given probability space $\probspace$ a stochastic process is a collection of random variables $\rvx(\omega, t) : \Omega \times T \rightarrow \mathbb{R}$ index by $T$ (i.e. $T=\R^{+}$ typically to represent time), which can be written as:
\begin{align*}
    \{\rvx(\omega, t) : t \in T\},
\end{align*}
\end{definition}
We typically adopt the notation $\rvx(t)$ since dependency on the sample space is usually dropped notationally, and more commonly in the statistics community the notation $X_t$ is used to emphasise that $T$ is an index set however we will be mostly using the function notation $\rvx(t)$ . 

Stochastic processes don't necessarily have to be limited to temporal processes as the examples we have given, in fact one of the most popular stochastic processes in Machine Learning , the Gaussian process (GP) for regression was initially devised for a spatial application known as Kriging. However in this thesis we will focus on the temporal case that is $T=\R^{+}$, furthermore we will also restrict ourselves to causal processes \footnote{Causal in the engineering and physics sense . i.e. Causal Green's function.} in that $\rvx(t)$ only depends on the present and the past. In order to formalise this notion of causality we require the concept of a filtration: 
\begin{definition}\label{def:filtration}
A filtration $\mathfrak{F} = (\calF_{t})_{i\in T}$ on probability space $\probspace$ is a sequence of indexed sub $\sigalg$ of $\calF$:
\begin{align*}
    \calF_{s} \subseteq \calF_{t} \subseteq \calF \quad \forall  s \leq t,
\end{align*}
we then call the space $\filtprobspace$ an $\mathfrak{F}$-filtered probability space.
\end{definition}
At a high level the construction in Definition \ref{def:filtration} is just creating an indexed sequence of events $(\calF_{t})_{i\in T}$ which now allows us to define processes that only depend on the past and present:
\begin{definition}\label{def:adapted}
    A stochastic process $\rvx$ is $\calF_t$-adapted  if $\rvx(t)$ is $\calF_t$-measurable:
    \begin{align*}
        \{\omega :\rvx(\omega,t) \in B\} \in \calF_t \quad \forall t \in T , \,\forall B \in \calB(\R^d).
    \end{align*}
\end{definition}
As mentioned before this definition is a formal way of stating that our stochastic process is only aware of past and present events.
\subsection{Wiener Process}

We will provide the definition of a causal Wiener process ($\calF_t$-adapted) since it is the type of processes that we will be working with. More generally Wiener processes do not have to be $\calF_t$-adapted.
\begin{definition}
    An $\calF_t$-adapted Wiener process (Brownian motion) is a stochastic process $\rvw(t)$ with the following properties:
    \begin{itemize}
        \item $\rvw(0) = \vzero$
        \item  $\rvw(t) - \rvw(s) \independent \calF_s$  for $s < t$ (independant increments).
        \item $\rvw(t) - \rvw(s) \sim \calN (t | \vzero,  (t - s) \I) $
        \item $\rvw(t)$ is continuous in $t$
    \end{itemize}
\end{definition}
A simpler way of looking at the above definition is by examining what the joint PDF for a set of observations $\rvw(t_1), ...., \rvw(t_n)$  is under this process:
\begin{align*}
    p(\rvw(t_1), ...., \rvw(t_n)) = \prod_{i=1}^{n-1} \calN\left(\rvw(t_{n+1})\big| \rvw(t_{n}), (t_{n+1}- t_{n})\I \right)
\end{align*}
From this we can see that $\calN\left(\rvw(t_{n+1})\big| \rvw(t_{n}), (t_{n+1}- t_{n})\I \right)$ shows us that the transition probability is given by a random increment  centered at  $\rvw(t_{n})$ i.e. :
\begin{align*}
    \rvw(t_{n+1}) = \rvw(t_{n}) +  \sqrt{(t_{n+1}- t_{n})}\rvz , \quad \rvz \sim \mathcal{N}(\vzero, \I) 
\end{align*}
We can also observe from the definition that a Wiener process is also a Gaussian Process (GP) more specifically a Gaussian Markov process parametrised by mean and covariance functions:
\begin{align*}
    \vm(t) = \vzero, \quad \vk(t, s) = \I\min(t, s)
\end{align*}

\subsection{Stochastic Integrals}

Stochastic integrals are the integrals induced by a stochastic process. Let's first consider the simplest type of stochastic integral, that is :

\begin{align} \label{eq:stochastic_sample}
    \int_{a}^{b} \rvx(t) dt
\end{align}

Where $\vx(\omega, t): \Omega \times T \rightarrow \R^d$ is a $\calF_t$-adapted stochastic process. These type of integrals appear in machine learning for example through Latent Force Models \cite{alvarez2009latent,alvarez2013linear} where the integrand $\rvx(t)$ is a Gaussian Process. The notation in Equation \ref{eq:stochastic_sample} whilst compact may initially seem confusing to the reader as $\rvx(t)$ is not a deterministic function and can effectively take on different values ?

To clarify the above we can express  Equation \ref{eq:stochastic_sample} in more detail:

\begin{align*}
    \int_{a}^{b} \rvx(\omega, t) dt \quad \forall \omega
\end{align*}

Basically we fix $\omega$ (i.e. condsider a single sampled random function) and the said resulting integral holds for all $\omega$.  Now we can define the above integral in the Riemann sense:
\begin{align*}
    \int_{a}^{b} \rvx(\omega, t) dt &= \lim_{ \max \Delta t \rightarrow 0} \sum_{i=1}^{n-1} \rvx(\omega, t_i^{*}) (t_{i+1} - t_i), \\
    \text{where} \;\; t_1 = a < &t_2 < \hdots < t_n = b, \;  t_i^{*} \in [ t_i, t_{i+1}]
\end{align*}
Where the convergence of the limit is defined in the mean square sense:
\begin{align*}
    \lim_{\max \Delta t \rightarrow 0} \E \left[ \Bigg|\Bigg|\sum_{i=1}^{n-1} \rvx(\omega, t_i^{*}) (t_{i+1} - t_i)-  \int_{a}^{b} \rvx(\omega, t) \Bigg|\Bigg|^2\right] =  0.
\end{align*}
Now all that is required for the above limit to exist is the following:
\begin{theorem}\label{thrm:ito_simple}
  If a stochastic process $\rvx(t)$ has continuous mean and covariance functions $\vm(t) = \E[\rvx(t)],\;\; \vk(t, s) = Cov(\rvx(t), \rvx(s))$, then the limit $\int_{a}^{b} \rvx(\omega, t) dt$ exists.
\end{theorem}
If Theorem \ref{thrm:ito_simple} holds true then analysing the resulting stochastic process that is produced by $\int_{a}^{b} \rvx(\omega, t) dt$ can be quite simple, for example as done in \cite{alvarez2009latent} where computing expectations and co-variances of the above integral to fully characterise the resulting process was sufficient.
 
\subsubsection{Itô  - Integral}
Things start to get more difficult if we consider integrals with respect to Brownian motion:
\begin{align}\label{eq:brownian_integral}
    \int_{a}^b \rvx(t) d\rvw(t)
\end{align}
First thing to note is that this takes the form of a Stieltjes integral in that it is with respect to another function $\rvw(t)$ (which in this case is a random function) rather than the domain of integration $t$. Naively defyning this integral as before is problematic since the limit is no longer well defined (unique) for this case:
\begin{align}\label{eq:brownian_integral_bad}
    \int_{a}^b \rvx(t) d\rvw(t) = \sum_{i=0}^{n-1} \rvx(t^{*}_i)(\rvw(t_{i+1}) - \rvw(t_i))
\end{align}
For the above limit to exist we require that the function $\rvw(\omega, t)$ has a bounded total variation in $t$ which it doesn't since Brownian motion paths do not have bounded total variation. However if we fix the choice $t_i^{*} = t_i$:
\begin{align}\label{eq:ito_integral}
    \int_{a}^b \rvx(t) d\rvw(t) = \sum_{i=0}^{n-1} \rvx(t_i)(\rvw(t_{i+1}) - \rvw(t_i)),
\end{align}
it can be shown that this limit will converge in the mean square sense. The above integral is known as the Itô-integral.
\subsection{Itô  - Process and SDEs}

For the purpose of this work Itô-Processes will be our definition of Stochastic Differential equations and we will use both terms to refer to the same object.

\begin{definition}
    For $\calF_t$-adapted stochastic processes $\rvb(t), \rvsigma(t)$ an Itô-process $\rvx(t)$ is defined as:
    \begin{align}\label{eq:ito_proc}
    \vx(t) = \rvx(0) + \int_{0}^t \rvb(s) ds + \int_0^t \rvsigma(s) d\rvw(s)
    \end{align},
Equation \ref{eq:ito_proc} is often notationally simplified to :
    \begin{align}\label{eq:sde_gen}
        d\vx(t) =\rvb(t) dt + \rvsigma(t) d\rvw(t)
    \end{align}
\end{definition}
The process $\rvb(t)$ we often refered to as the drift and $\rvsigma(t)$ as the volatility. The notation in Equation \ref{eq:sde_gen} is what we typically refer to as a stochastic differential equation since if we "divide" both sides by $dt$ we obtain:
\begin{align*}
    \frac{d \rvx(t)}{dt} = \rvb(t) + \rvsigma(t) \rvepsilon(t),
\end{align*}
where $\rvepsilon(t) \sim \calN(\vzero, \delta(k-s)\I)$ is white noise and is regarded as the derivative of Brownian motion (in some sense). One must be careful with the above representation and note that it is only national since most stochastic processes are not differentiable (i.e. Brownian motion).
Note that SDE's effectively describes the dynamical evolution of a random variable in time, and thus one may want to ask what is the density of such random variable. For Itô-Processes of the form:
\begin{align}\label{eq:parametric_ito}
     d\vx(t) =\vb(\vx(t), t) dt + \rvsigma(\vx(t), t) d\rvw(t),
\end{align}
where $\vb : \R^d \times \R^{+} \rightarrow \R^d$ and $\rvsigma : \R^d \times \R^{+} \rightarrow \R^{d\times d}$ are deterministic functions that parametrise the drift and volatility respectively, we can define a partial differential equation (PDE) that describes the evolution of the PDF as a function of time:
\begin{definition}\label{def:fpk}
    For an Itô-Process following the form of Equation \ref{eq:parametric_ito}, the Fokker-Plank (FPK) Equation has the form:
    \begin{align}\label{eq:fpk}
        \partial_{t} p(\vx, t) =-\nabla \cdot p(\vx, t)\vb(\vx(t), t) + \frac{1}{2} \sum_{ij} \partial^2_{{x_i}{x_j}}[\rvsigma(\vx(t), t)\rvsigma(\vx(t), t)^{\top}]_{ij},
    \end{align}
    where $p(\vx, t)$ is the probability density function of the solution of the the SDE equation.
\end{definition}
The FPK equation thus provides us with an alternate representation for the solution of SDEs via a PDE whose solution describes a PDF.

\subsubsection{Itô's-Rule}

At a high level Itô's-Rule is the equivalent to the change of variables rule for integration. We wont be going into much technical details explaining how to arrive to this rule but we will be restating it here used in some of our results. 

\begin{theorem}
  (Itô's-Rule) Assume that $\rvx(t)$ is an Itô process and consider an arbitrary scalar function $f(\rvx(t), t)$ of the process. Then the Itô SDE for $f$ is given by:
  \begin{align}\label{eq:ito_rule}
      df = \partial_t f dt + \sum_i \partial_{{x_i}} f dx_i + \frac{1}{2}\sum_{ij} \partial^2_{{x_i}{x_j}} f dx_i dx_j,
  \end{align}
  provided that the required partial derivatives exist. 
\end{theorem}
\begin{proof}
See \cite{oksendal2003stochastic}.
\end{proof}
Note that the above is very similar to standard change of variables formula with the difference that an extra quadratic term for more intuition behind this result see \cite[Chapter~4]{sarkka2019applied}.
\section{Radon-Nikodym Derivative}

The RN-Theorem allows us to write a probability measure in terms of an integral with respect to another probability measure. 

\begin{theorem}
(Radon-Nikodym Theorem)
Given probability measures $\P$ and $\Q$ defined on the measurable space $\Omega, \calF$. There exists a measurable function $\frac{d\P}{d\Q}:\Omega \rightarrow [0, \infty)$ , then for any  set $A \subseteq  \Omega$:
\begin{align}
    \P(A) = \int_{A} \frac{d\P}{d\Q}(\vx) d\Q(\vx),
\end{align}
where the function $\frac{d\P}{d\Q}(\vx)$ is known as the RN-derivative.
\end{theorem}

A direct consequence of this result is:
\begin{align*}
    \int_A f(\vx) d\P(\vx) =  \int_{A} f(\vx)  \frac{d\P}{d\Q}(\vx)  d\Q(\vx)
\end{align*}

This change of measure above is analogous to the trick carried out when we do importance sampling. The RN-derivative is effectively the same as the importance sample weights and it in-fact reduces to a ratio of PDF's for the case when the PDF's of the respective distributions are available.
\begin{figure}[t!]
    \centering
    \includegraphics[scale=0.5]{images/disint2.png}
    \caption{ One can see that its is possible to construct a conditional measure to calculate the size of the green rectangle, however under the joint measure such measure is $0$. The disintegration Theorem provides us with the construction of such conditional measure.}
    \label{fig:disintegration}
\end{figure}
\subsection{Disintegration Theorem and Conditional Measures}

In this section we will present the disintegration theorem in the context of probability measures. We will use this theorem to present a derivation for RN-derivative equivalent of the product rule.

\begin{theorem} (Disintegration Theorem , for continuous probability measures): 

For a probability space $(Z, \calB(Z) ,\P)$ where $Z$ is a product space: $Z = Z_x \times Z_y$ and:
\begin{itemize}
    \item  $Z_x \subseteq \R^d, Z_y \subseteq \R^{d'}$
    \item  $\pi_i: Z \rightarrow Z_i$ be a measurable function known as the canonical projection operator ( i.e. $\pi_x(z_x,z_y) = z_x$ and $\pi^{-1}(z_x) = \{y | \pi(z_x) = z\}$)
\end{itemize}
Then there exists a measure $\P_{y|x}(\cdot | \vx)$ such that:
  \begin{align}
      \int_{Z_x \times Z_y} f(\vx, \vy) d\P(\vy) = \int_{Z_x}\int_{Z_y} f(\vx,\vy) d\P_{y|x}(\vy | \vx) d\P(\pi^{-1}(\vx)),
  \end{align}
 where $P_x(\cdot) = \P(\pi^{-1}(\cdot))$  is a probability measure typically refered to as a pullback measure and corresponds to the marginal distribution.
\end{theorem}

A direct consequence of the above instance of the disintegration theorem is the following, let $f(\vx,\vy) = \ind_{A_x \times A_y}(\vx,\vy)$:
\begin{align}
    \P(A_x \times A_y) = \int_{A_x}\P(A_y | \vx) d\P_x(\vx) 
\end{align}
 We can see that in the context of probability measures the above is effectively an analogue to the product rule 

We now have the required ingredients to show the following:
\begin{lemma}\label{lemma:rn_des}( RN-derivative product rule)
Given two probability measures defined on the same product space,  $(Z_x \times Z_y, \calB(Z_x \times Z_y) ,\P)$ and $(Z_x \times Z_y, \calB(Z_x \times Z_y) ,\Q)$, the Radon–Nikodym $\frac{d\P}{d\Q} (\vx,\vy)$ derivative can be decomposed as:
\begin{align}
    \frac{d\P}{d\Q} (\vx,\vy) = \frac{d\P_{y|x}}{d\Q_{y|x}}(\vy)\frac{d\P_x}{d\Q_x}(\vx)
\end{align}
\end{lemma}
\begin{proof}

Starting from:
\begin{align*}
    \P(A_x \times A_y) =  \int_{A_x}\P(A_y | \vx)  d\P_{x}(\vx) 
\end{align*}
We apply the Radon-Nikodym Theorem to $\P(A_y | \vx)$ and then to $P_x$:
\begin{align*}
    \P(A_x \times A_y) &=  \int_{A_x}\int_{A_y} \frac{d\P_{y|x}}{d\Q_{y|x}}(\vy) d\Q_{y|x}(\vy) d\P_{x}(\vx) \\
     &= \int_{A_x}\left(\int_{A_y} \frac{d\P_{y|x}}{d\Q_{y|x}}(\vy) d\Q_{y|x}(\vy)\right) \frac{d\P_{x}}{d\Q_{x}}(\vx)d\Q_{x}(\vx) \\
      &= \int_{A_x}\int_{A_y}\frac{d\P_{x}}{d\Q_{x}}(\vx)\frac{d\P_{y|x}}{d\Q_{y|x}}(\vy) d\Q_{y|x}(\vy) d\Q_{x}(\vx)
\end{align*}
Now  via the dissintegration we have that:
\begin{align*}
  \int_{A_x \times A_y} \frac{d\P_{x}}{d\Q_{x}}(\vx)\frac{d\P_{y|x}}{d\Q_{y|x}}(\vy) d\Q(\vx,\vy) = \int_{A_x}\int_{A_y}\frac{d\P_{x}}{d\Q_{x}}(\vx)\frac{d\P_{y|x}}{d\Q_{y|x}}(\vy) d\Q_{y|x}(\vy) d\Q_{x}(\vx)
\end{align*}
Thus we conclude that:
\begin{align*}
    \P(A_x \times A_y) = \int_{A_x \times A_y} \frac{d\P_{x}}{d\Q_{x}}(\vx)\frac{d\P_{y|x}}{d\Q_{y|x}}(\vy) d\Q(\vx,\vy), 
\end{align*}
which via the Radon-Nikodym Theorem imlpies:
\begin{align*}
    \frac{d\P}{d\Q} (\vx,\vy) = \frac{d\P_{y|x}}{d\Q_{y|x}}(\vy)\frac{d\P_x}{d\Q_x}(\vx).
\end{align*}
\end{proof}
The above result is used across a variety of different texts in stochastic processes, nonetheless it has proven difficult to find a resource for it and its derivation. We searched through a variety of graduate courses and books on measure and integration and could not find this result neither stated nor derived thus we decided it would be instructive to provide a sketch proof for it, since we will be using it multiple times.


\subsection{RN-Derivative of Itô-Processes}


As we hinted earlier Itô-processes don't admit a PDF since they are note absolutely continuous with respect to the Lebesgue measure. However some Itô-processes are absolutely continuous with respect to one another and thus we are able to compute their RN-derivatives which is useful if we want to compute the KL-divergence between the two processes.  First we must introduce the following notation:
\begin{definition} (Path Measure)
    For an Itô-process of the form:
    \begin{align*}
        d\rvx(t) = \rvb(t) + \rvsigma(t) d\rvw(t)
    \end{align*}
    defined in $[0,T]$. We call $\P$ the path measure of the above process whose outcome space $\Omega=C([0,T], \R^d)$ if the distribution $\P$ describes a weak solution to the above SDE \footnote{Weak solution is a terminology for a solution of an SDE that does not take into account an initial value problem.} to the above SDE.
\end{definition}

In short the path measure represents the probability measure associated to the stochastic process specified by the SDE. 

Now we can go ahead and present the following Theorem \citep{sarkka2019applied}:
\begin{theorem}\label{thrm:ito_ratio}\citep{sarkka2019applied}
Given two Itô-processes with the same constant volatility: 
    \begin{align*}
        d\rvx(t) = \rvb_1(t) + \sigma \rvw(t) \quad \rvx = \rvx_0\\
        d\rvy(t) = \rvb_2(t) + \sigma\rvw(t) \quad \rvy = \rvx_0
    \end{align*}
The RN-Derivative of their respective path measures $\P,\Q$ is given by:
\begin{align} \label{eq:girsanov}
    \frac{d\P}{d\Q}(\cdot) = \exp\left(-\frac{1}{2\sigma^2}\int_0^t ||\rvb_1(s) - \rvb_2(s)||^2 ds + \frac{1}{\sigma^2}\int_0^t (\rvb_1(s) - \rvb_2(s))^{\top}d\rvw(s) \right)
\end{align}
\end{theorem}
Note that in the case where we take the RN-derivative with respect to Brownian motion (i.e. $\rvb_2(t) =0, \; \sigma=1$), we have the following expression:
\begin{align} \label{eq:girsanov_0}
    \frac{d\P}{d\W}(\cdot) = \exp\left(-\frac{1}{2}\int_0^t ||\rvb_1(s) ||^2 ds + \int_0^t \rvb_1(s)^{\top}d\rvw(s) \right),
\end{align}
which is popularly refered to as Girsanov's theorem as it is one of the main elements in said theorem.
%\chapter{Background} 
\chapter{The Schrödinger Bridge Problem}

As originally posed by Schrödinger in \citep{schrodinger1931uber, schrodinger1932theorie} the Schrödinger Bridge consists in finding a posterior stochastic evolution between two distributions that is optimally close to a Brownian motion prior in a KL sense:
\begin{align} \label{eq:schrobirdge}
    \hat{\Q}= \argmin_{\Q \in \calD(\pi_0, \pi_1)} \KL\left(\Q \big|\big| \W\right),
\end{align}
where:
\begin{align} \label{eq:schrobirdge}
    \ \KL\left(\Q \big|\big| \W\right) = \E_{\Q}\left[\ln \frac{d\Q}{d\W}\right].
\end{align}
To the eye of a probabilistic modeller this objective may be initially quite confusing.  Mainly because it is minimising the KL divergence between a "posterior" distribution $\Q$ and a "prior" distribution $\W$ which does not match the usual variational inference objectives that arise from minimising an Evidence Lower Bound. In order to give a sound interpretation to the objective in Equation \ref{eq:schrobirdge} we will look into the Schrödinger Bridge's formulation as a rare event and additionally comment on the maximum entropy like nature of the objective.

\section{Rare Events and Maximum Entropy }

First let our sample space be the space of random functions with the unit interval as pre-image $C([0,1], \R^d)$ that is a sample  represents a function of the form $\vx : [0, 1]:  \rightarrow \R^d$.  We now take a set of i.i.d samples $\{\rvx_{i}(t)\}_{i=1}^N$ following standard Brownian motion defined on $C([0,1], \R^d)$. The empirical distribution for $\{\rvx_{i}(t)\}_{i=1}^N$ is the defined by:
\begin{align}\label{eq:empirical}
    \hat{\W}(A) = \frac{1}{N}\sum_{i=1}^N \ind\left(\rvx_i(t) \in A\right)  , \quad A \in \calB(\R^d)^{[0,1]},
\end{align}
then we might want to ask what is the probability that the empirical distribution prescribes marginals $\pi_0, \pi_1$ which cannot be attained by Brownian motion:
\begin{align}
    {P}\left(\hat{\W} \in \mathcal{D}(\pi_0, \pi_1) \right)
\end{align}
it turns out that result from the theory of large deviations (Sanov's Theorem) allows us to compute an asymptotic expression for such probability:
\begin{align} \label{eq:max_ent}
    {P}\left(\hat{\W} \in \mathcal{D}(\pi_0, \pi_1) \right) \sim \exp\left(-N\inf_{\Q \in \calD(\pi_0, \pi_1)} \!\!\!\!\!\KL\left(\Q \big|\big| \W\right)\right).
\end{align}
For a more technically thorough introduction please check \cite{leonard2013survey}. Note that the exponent for the probability in Equation \ref{eq:max_ent} extremises the KL-divergence following the Principle of Minimum Discrimination Information by \cite{kullback1997information} which is a generalisation of Edwin Jane's Maximum Entropy Principle \citep{jaynes1957information,jaynes2003probability} to continuous distributions. Note one can observe the connection between maximising entropy and minimising KL divergence by considering the discrete setting where minimising KL divergence with respect to a uniform reference distribution is equivalent to maximising entropy. In simple words we are selecting a distribution $\hat{\Q}$ subject to the marginal constraints that is as close as possible given prior knowledge $\W$.

\section{Dynamic Formulation}
The Dynamic formulation of the Schrödinger follows directly from the exponent in the maximum entropy formulation.  The dynamic version of the Schrödinger bridge is written in terms of path measures that describe the stochastic dynamics defined over the unit interval.
\begin{definition}
    (Dynamic Schrödinger Problem) The dynamic Schrödinger problem is given by:
    \begin{align}
        \inf_{\Q \in \calD(\pi_0, \pi_1)} \KL\left(\Q \big|\big| \W^{\gamma}\right)
    \end{align}
    Where $\Q \in \calD(\pi_0, \pi_1)$ is a path measure with prescribed marginals of $\pi_0, \pi_1$ at times $0, 1$ and $\W_{\gamma}$ is the Wiener measure with volatility $\gamma$. 
\end{definition}
\subsection{As a Stochastic Control Problem}

The two results presented below are from \cite{pavon1991free}. For Pedagogical reasons we provide a proof sketch of these two results.

We can represent $\Q$ as the distribution which evolves according to the solution of an SDE of the form:
\begin{align*}
    d\rvx(t) = \rvb^{+}_t dt + \sqrt{\gamma} \rvw(t)
\end{align*}
\begin{lemma}\citep{pavon1991free}
    The KL Divegence between $\Q$ and $\W_{\gamma}$ can be decomposed as:
\begin{align}\label{eq:free_energy_1}
     \KL\left(\Q \big|\big| \W^{\gamma}\right) = \KL(\pi^{\Q}_0 || \pi_0) + \E_\Q\left[\int_0^1 \frac{1}{2\gamma}\big|\big|\rvb^{+}_t \big|\big|^2 dt\right]
\end{align}
\end{lemma}
\begin{proof}
Via the Disintegration theorem and Theorem \ref{lemma:rn_des} we can condition on the endpoint and re-write the RN derivative as:
\begin{align*}
    \frac{d\Q}{d\W} = \frac{\pi_0^\Q}{\pi_0} \frac{d\Q_{(0,1]}}{d\W_{(0,1]}}\left(\cdot | \rvx(0) =\vx\right)
\end{align*}
where the disintegration $\Q_{(0,1]}\left(\cdot | \rvx(0) = \vx \right)$ is a solution $d\rvx(t) = \rvb_t dt + \gamma \rvw(t), \; \rvx(0) \sim \pi_0^\Q$ then by Theorem \ref{thrm:ito_ratio} we can express the RN-derivative in terms of  drift $\vb(\rvx(t), t)$:
\begin{align*}
    \frac{d\Q}{d\W} = \frac{\pi_0^\Q}{\pi_0}\exp\left(\int_0^1\frac{1}{2\gamma} \big|\big|\rvb^+_t\big|\big|^2 dt\right),
\end{align*}
Now substituting the above back into the KL divergence completes the result for Theorem \ref{eq:free_energy_1}.
\end{proof}
Now we can equivalently express $\Q$ as the solution to a reverse time diffusion :
\begin{align}
    d\rvx(t) = \rvb^{-}_tdt + \sqrt{\gamma} \rvw^{-}(t), 
\end{align}
where $\rvx(t)$ is adapted to the reverse filtration $(\calF^{-}_i)_{i\in T}$ that is $\calF^{-}_t \subseteq \calF^{-}_s \; s \leq t $ \footnote{As mentioned before this just means $\rvx(t)$  is only aware about the future}.  Where:
\begin{align}\label{eq:nelson}
    {\rvb^{+}_t - \rvb^{-}_t} = \nabla_{\vx} p(\rvx(t), t).
\end{align}
Where $p(\rvx(t), t)$ is the solution to the FPK equation. The above is typically known as Nelson's duality equation and it relates the forwards drift to the dual backwards drift \citep{nelson1967dynamical}. 

Using reverse diffusion \cite{pavon1991free} decompose the KL divergence as done with the forward diffusion:
\begin{lemma}\citep{pavon1991free}
    The KL Divegence between $\Q$ and $\W_{\gamma}$ can be decomposed as:
\begin{align}\label{eq:free_energy_1}
     \KL\left(\Q \big|\big| \W^{\gamma}\right) = \KL(\pi^{\Q}_1 || \pi_1) + \E_\Q\left[\int_0^1\frac{1}{2\gamma} \big|\big|\rvb^{-}_t\big|\big|^2 dt\right]
\end{align}
\end{lemma}
Then using the drift based formulations defined above \cite{pavon1991free} derive alternate (yet equivalent) objectives for the Schrödinger Bridge objective:

\begin{itemize}
\item Forward Objective: 
\begin{align} \label{eq:controlled_bridge_forward}
    \min_{\Q \in \calD(\pi_0, \pi_1)} \KL\big(\Q \big|\big| \W^{\gamma}\big)& = \min_{\rvb^{+} \in \calB }  \E_\Q\left[\int_0^1 \frac{1}{2\gamma}\big|\big|\rvb^{+}_t \big|\big|^2 dt\right] \nonumber \\
    s.t.\;\;\; d\rvx(t) = \rvb^{-}_t &dt + \sqrt{\gamma} \rvw(t), \;\; \rvx(0) \sim \pi_0, \;\; \rvx(1) \sim \pi_1
\end{align}
\item Backward Objective
\begin{align} \label{eq:controlled_bridge_backward}
    \min_{\Q \in \calD(\pi_0, \pi_1)} \KL\big(\Q \big|\big| \W^{\gamma}\big)& = \min_{\rvb^{-} \in \calB }  \E_\Q\left[\int_0^1 \frac{1}{2\gamma}\big|\big|\rvb^{-}_t \big|\big|^2 dt\right] \nonumber \\
    s.t.\;\;\; d\rvx(t) = \rvb^{+}_t &dt + \sqrt{\gamma} \rvw^{-}(t), \;\; \rvx(1) \sim \pi_1 , \;\; \rvx(0) \sim \pi_0
\end{align}.
\end{itemize}
Notice that the conditioning carried out by the Disintegration theorem allows us to remove one of the boundary constraints and integrate it as an initial value problem to the objective. This result is what inspired us the most in the design of an iterative algorithm for solving finding the Schrödinger Bridge numerically. 
\section{Static Formulation}
\begin{definition}\label{def:static_bridge}
    (Static Schrödinger Problem) The static Schrödinger bridge consists in finding the joint distribution $q(\vx, \vy) \in \calD(\pi_0(\vx), \pi_1(\vy))$ which is closest to the Brownian motion prior, subject to marginal constraints, that is :
    \begin{align}\label{eq:static_bridge}
        \inf_{q(\vx,\vy)} \KL (q(\vx,\vy)  &|| p^{\W^{\gamma}}(\vx,\vy)) \nonumber \\
        s.t. \;\;\; \pi_0(\vx) = \int q(\vx,\vy) d\vy, &\;\;\pi_1(\vy) = \int q(\vx,\vy) d\vx,
    \end{align}
\end{definition}
we will know illustrate how this result is arrived to from the dynamic version. Most surveys and paper relating the Schrödinger include some form of the derivation that we are about to present, however they skip several steps which may make it inaccessible to a more applied community. 
\begin{theorem}\citep{follmer1988random}
    The dynamic Schrödinger bridge is solved by :
\begin{align}
    \Q^{*} (\cdot) =  \int \W^{\gamma} \left(\cdot | \vx, \vy\right)  q^{*}(\vx,\vy) d\vx d\vy 
\end{align}
    where $q^*$ is the optimal density that solves the static bridge:
    \begin{align*}
        q^{*}(\vx,\vy)& = \arginf_{q(\vx,\vy)} \KL (q(\vx,\vy)  || p^{\W^{\gamma}}(\vx,\vy))  \\
        s.t. \;\;\; \pi_0(\vx) &= \int q(\vx,\vy) d\vy, \;\;\pi_1(\vy) = \int q(\vx,\vy) d\vx,
    \end{align*}
    and :
    \begin{align*}
        \W^{\gamma} \left(\cdot | \vx, \vy\right)  = \W_{(0,1)}^{\gamma}\left(\cdot | \rvx(0) =\vx, \rvx(1) =\vy\right),
    \end{align*}
    Is the conditional (disintegration) of the Wiener measure about its endpoints.
\end{theorem} %\vspace{-0.6cm}
\begin{proof}
Firstly we decompose the KL divergence over path measures $\KL\left(\Q \big|\big| \W\right)$ using Lemma \ref{lemma:rn_des}, conditioning on the endpoints $\rvx(0), \rvx(1)$ we can re-express the RN-derivative as:
\begin{align}
    \frac{d\Q}{d\W} = \frac{q(\vx, \vy)}{p^{\W^{\gamma}}(\vx. \vy)}\frac{d\Q_{(0,1)}}{d\W_{(0,1)}}\left(\cdot | \rvx(0) =\vx, \rvx(1) =\vy\right)
\end{align}
Let $\Q_{(0,1)}(\cdot |  \rvx(0) =\vx, \rvx(1) =\vy) = \Q(\cdot |  \vx,\vy)$. Substituting the above decomposition back into the KL divergnece and marginalising where possible we arrive at: 
\begin{align} \label{eq:follmer_kl}
    \KL\left(\Q \big|\big| \W\right) =&  \KL\left(q(\vx, \vy) \big|\big| p^{\W^{\gamma}}(\vx. \vy) \right)  + \E_{\Q}\left[\frac{d\Q}{d\W^\gamma}\left(\cdot | \vx, \vy\right)\right], \nonumber \\
    =&  \KL\left(q(\vx, \vy) \big|\big| p^{\W^{\gamma}}(\vx. \vy) \right)  + \E_{q(\vx,\vy)}\left[\KL\left(\Q(\cdot |  \vx,\vy)\big|\big|\W^{\gamma}(\cdot |  \vx,\vy)\right)\right].
\end{align}
Now notice that the conditional $\Q_{(0,1)}(\cdot |  \rvx(0) =\vx, \rvx(1) =\vy)$ is not affected by the boundary constraints thus we can set $\Q(\cdot | \vx,\vy) = \W^\gamma\left(\cdot | \vx, \vy\right)$ making the second term 0, and leaving us with the static bridge. It then suffices to reverse the Disintegration theorem in order to build up $\Q^{*}$ from $q^{*}$ and $\Q^{*}(\cdot | \vx,\vy)$ completing the proof.
\end{proof}

The earliest references we found for the above result are given by \cite{follmer1988random}, where the decomposition of the KL divergence for two diffusion's (Equation \ref{eq:follmer_kl}) is provided. However we were not able to find a good reference for Lemma \ref{lemma:rn_des} and thus we have provided an instructive derivation for it.
\subsection{As an Entropy Regularised Optimal Transport Problem}

Here we will present and discuss a very well studied \citep{mikami2008optimal,leonard2012schrodinger,leonard2013survey,carlier2017convergence} connection between the static bridge and the Wasserstein distance.  Using that for the Wiener process $\W^\gamma$ prior we have :
\begin{align}
    p^{\W^{\gamma}}(\vx,\vy) = p^{\W^{\gamma}}_0(\vx)\calN(\vy | \vx, \sqrt{\gamma}\I)
\end{align}
and that the term:
\begin{align*}
    \int q(\vx, \vy)\ln  p^{\W^{\gamma}}_0(\vx) d\vx d\vy =  \int \pi_0(\vx) \ln  p^{\W^{\gamma}}_0(\vx) d\vx  
\end{align*}
does not depend on $q$ (due to the constraints). Substituting the above into Equation \ref{eq:static_bridge} we arrive at:
\begin{align}
    &\inf _{q \in \calD(\pi_0, \pi_1)}\int \int -\frac{||\vx - \vy ||^2}{2\gamma} q(\vx, \vy) d\vx d\vy  + \int \int q(\vx, \vy) \ln q(\vx, \vy) d\vx d\vy \nonumber \\
    &=\inf _{q \in \calD(\pi_0, \pi_1)}\int \int -\frac{||\vx - \vy ||^2}{2} q(\vx, \vy) d\vx d\vy  - \gamma \text{H} \left(q(\vx, \vy)\right)
\end{align}
which is an entropy regularised optimal mass transport problem (OMT) \citep{villani2003topics} with a quadratic cost function. Furthermore as the volatility/noise of the Brownian motion prior goes to 0 ($\gamma \downarrow 0$) the above quantity converges to $\calW^2_{2}(\pi_0, \pi_1)$ (Squared Wasserstein distance in an $L_2$ metric space).
\subsection{The Schrödinger System}

Following \cite{pavon2018data} Lagrangian of Equation \ref{eq:static_bridge} is given by :
\begin{align}\label{eq:schro_lagrangian}
    \calL(q, \lambda,  \mu) &=  \KL (q(\vx,\vy)  || p^{\W^{\gamma}}(\vx,\vy))  \nonumber\\
    &+ \int \lambda(\vx)\left( \int q(\vx,\vy)d\vy -\pi_0(\vx)\right)d\vx \nonumber \\
    &+ \int \mu(\vy) \left(\int q(\vx,\vy) d\vx - \pi_1(\vy)\right) d\vy
\end{align}
Let $p^{\W^{\gamma}}(\vx,\vy) = p^{\W^{\gamma}}_0(\vx)p^{\W^{\gamma}}(\vy|\vx)$. Where $p^{\W^{\gamma}}_0(\vx)$ is the marginal prior which we are free to set and $p^{\W^{\gamma}}(\vy|\vx)=\calN(\vy | \vx, \sqrt{\gamma}\I)$ is the transition density of the prior. Then we set functional derivative $\frac{\delta \calL}{\delta q(\vx, \vy)}$ to 0 and obtain:
\begin{align*}
    1 + \ln q(\vx, \vy)  - \ln p^{\W^{\gamma}}(\vy|\vx)
    - \ln p^{\W^{\gamma}}_0(\vx)+ \lambda(\vx)
+ \mu(\vy) = 0, \nonumber
\end{align*}
rearranging:
\begin{align*}
{q^{*}(\vx, \vy) }  = \exp\left(  \ln p^{\W^{\gamma}}_0(\vx) -\lambda(\vx) -1\right)p^{\W^{\gamma}}(\vy|\vx)\exp\left(- \mu(\vy)\right) \nonumber
\end{align*}
which we can re-express in terms of the auxiliary potentials $\hphi_0(\vx), \phi_1(\vy)$:
\begin{align*}
{q^{*}(\vx, \vy) }  = \hphi_0(\vx)p^{\W^{\gamma}}(\vy|\vx)\phi_1(\vy), \nonumber
\end{align*}
satisfying:
\begin{align}
    \hphi_0(\vx) \int \phi_1(\vy) p^{\W^{\gamma}}(\vy|\vx) d\vy = \pi_0(\vx)  \nonumber\\ 
    \phi_1(\vy) \int \hphi_0(\vx) p^{\W^{\gamma}}(\vy|\vx) d\vx = \pi_1(\vy), \nonumber
\end{align}
where we re-lable the terms with the integrals to:
\begin{align}
    \phi_0(\vx) &= \int \phi_1(\vy) p^{\W^{\gamma}}(\vy|\vx) d\vy \nonumber\\ 
    \hphi_1(\vy) &= \int \hphi_0(\vx) p^{\W^{\gamma}}(\vy|\vx) d\vx. \nonumber
\end{align}
Placing it all together, the following linear functional system is known as the Schrödinger system:
\begin{align}
    \hphi_0(\vx) \phi_1(\vx)  = \pi_0(\vx)  \nonumber \\ 
    \hphi_1(\vx) \phi_1(\vy)  = \pi_1(\vy).
\end{align}
To obtain the distribution $\pi^{*}_t(\vz)$ (Solution to the FPK equation for the optimal $Q^{*}$) :
\begin{align}
    \pi^{*}_t(\vz) =  \hphi_t(\vz) \phi_t(\vz) 
\end{align}
where:
\begin{align}
    \phi_t(\vz) &= \int \phi_1(\vy(1) ) p^{\W^{\gamma}}(\vy(1)|\vz(t)) d\vy(1) \nonumber\\ 
    \hphi_t(\vz) &= \int \hphi_0(\vx(0)) p^{\W^{\gamma}}(\vz(t)|\vx(0)) d\vx(0). \nonumber
\end{align}
Note that by Theorem X of \cite{pavon1991free} the optimal control signal/drift $\rvb_t^+$ can be recoverd from the solution of the Schrödinger system:
\begin{align} \label{eq:drifr_potential}
    \rvb_t^{+} = \gamma \nabla \ln \phi_t(\vx(t) )
\end{align}
\subsection{Half Bridges}

The half bridge problem as presented in \cite{pavon2018data} is a simpler variant of the full Schrödinger bridge with only one boundary constraint. 

\begin{definition}
The forward half bridge is given by:
    \begin{align}
        {\P}^{*} = \inf_{\P  \in \calD(\pi_0, \cdot)} \KL (\P || \W) 
    \end{align}
\end{definition}
\begin{theorem}\label{thrm:half_bridge_forward}
    The forward half bridge admits the following solution: 
\begin{align}
    {\P}^{*}\left(A_0 \times A_{(0,1]}\right) =  \int_{A_0\times A_{(0,1]}} \frac{d \pi_0}{ dp_0^\W} d\W
\end{align}
\end{theorem}
\begin{proof}
Via the disintegration theorem we have the following decomposition of KL
\begin{align}
    \KL(\P || \W) = \KL(p|| \pi_0 )  + \E_p\left[\KL(\P(\cdot| \vx) || \W(\cdot | \vx))\right] \nonumber
\end{align}
Thus via matching the terms accordingly we can construct $\hat{P}$ to set the second term to $0$ and match the constraints:
\begin{align}
    {P}^{*}\left(A_0 \times A_{(0,1]}\right) = \int_{A_0 \times A_{(0,1]}}\!\!\!\!\!\!\!\!\!\!\!\!\W(A_{(0,1]} | \vx) d\pi_0(\vx)
\end{align}
\begin{align}
    {P}^{*} &= \int_{A_0}  \frac{d\pi_0}{dp_0^\W}(\vx)   \W(\cdot | \vx) d p^\W(\vx) \nonumber \\
    &= \int_{A_0 \times A_{(0,1]} }  \frac{d\pi_0}{dp_0^\W}(\vx)  d \W
\end{align}
\end{proof}
\begin{definition}
The backwards half bridge is given by:
    \begin{align}
        {\Q}^{*} = \inf_{\Q  \in \calD(\cdot, \pi_1)} \KL (\Q || \W) 
    \end{align}
\end{definition}
\begin{theorem}\label{thrm:half_bridge_backward}
     The backward half bridge admits the following solution: 
\begin{align}
    {\Q}^{*}\left( A_{[0,1)} \times A_1\right) =  \int_{ A_{[0,1)} \times A_1}  \frac{d \pi_1}{ d p_0^\W} d\W
\end{align}

\end{theorem}
\begin{proof}
Same as Theorem \ref{thrm:half_bridge}.
\end{proof}


Note how the main difference between the full and half bridges is that the half bridges admit a closed form solution in terms of known quantities. Similarly to the full bridge the half bridges admit a static formulation:

\begin{definition}
The static forward bridge is given by the following objective
 \begin{align}\label{eq:static_bridge_forward}
        \inf_{q(\vx,\vy)} \KL  &(q(\vx,\vy) || p^{\W^{\gamma}}(\vx,\vy)) \nonumber \\
        s.t. \;\;\;& \pi_0(\vx) = \int q(\vx,\vy) d\vy, 
\end{align}
\end{definition}
\begin{theorem}\label{thrm:static_half_forward}
     The static forward bridge admits the following solution:
     \begin{align}
         q^{*}(\vx,\vy) = p^{\W_{\gamma}}(\vx, \vy)\frac{\pi_0(\vx)}{p^{\W_{\gamma}}(\vx)}
     \end{align}
\end{theorem}
\begin{proof}
See \cite{pavon2018data} for the solution of the backward half bridge. Proof is simple and easy to adapt to the forward bridge. 
\end{proof}
\begin{definition}
The static backward bridge is given by the following objective
 \begin{align}\label{eq:static_bridge_backward}
        \inf_{q(\vx,\vy)} \KL  &(q(\vx,\vy) || p^{\W^{\gamma}}(\vx,\vy)) \nonumber \\
        s.t. \;\;\;& \pi_1(\vy) = \int q(\vx,\vy) d\vx, 
\end{align}
\end{definition}
\begin{theorem}\label{thrm:static_half_backward}
     The static backwards bridge admits the following solution:
     \begin{align}
         q^{*}(\vx,\vy) = p^{\W_{\gamma}}(\vx, \vy)\frac{\pi_1(\vy)}{p^{\W_{\gamma}}(\vy)}
     \end{align}
\end{theorem}
\begin{proof}
See \cite{pavon2018data}.
\end{proof}


%\chapter{Algorithmic Framework} 
\chapter{Iterative Proportional Fitting Procedure}

So far we have introduced the Schrödinger bridge problem as well as its simpler half bridge variants. We have also introduced the Schrödinger system and loosely hinted at a potential iterative solution, nonetheless we have not yet presented a full solution and discussed its guarantees / properties.

In this chapter we will be studying an algorithmic framework known as the Iterative Proportional Fitting Procedure (IPFP) \citep{csiszar1975divergence, kullback1968probability, ruschendorf1995convergence,cramer2000probability} and describe its usage for solving the Schrödinger bridge. Furthermore we will formalise a previously made observation that connects Fortet's Iterative scheme \citep{fortet1940resolution} for solving the Schrödinger system with the more general IPFP . 

\section{Fortet's Algorithm}

Firstly let us start by introducing Fortet's algorithm, which is probably the oldest algorithm with a proof of convergence \cite{fortet1940resolution} for solving the Schrödinger system.

\begin{algorithm} \label{alg:fortet}
\SetKwInOut{Input}{input}
\Input{$\pi_0(\vx), \pi_1(\vy), p(\vy | \vx)$}
Initialise $\phi_0^{(0)}(\vx)$ such that $\phi_0^{(0)}(\vx) <\!< \pi_0(\vx)$ \\
    \Repeat{convergence}{
      $\hphi_0^{(i)}(\vx) := \frac{\pi_0(\vx)}{\phi_0^{(i)}(\vx)}$ \\
      $\hphi_1^{(i)}(\vy) := \int  p(\vy | \vx) \hphi_0^{(i)}(\vx) d\vx$ \\
      $\phi_1^{(i)}(\vy) := \frac{\pi_1(\vy)}{\hphi_1^{(i)}(\vy)}$ \\
      $\phi^{(i+1)}_0(\vx) := \int  p(\vy | \vx) \phi_1^{(i)}(\vy) d\vy$\\
      $i:=i+1$
    }
\Return{$\hphi_0^{(i)}(\vx), \phi_1^{(i)}(\vy)$}
\caption{Fortet's Iterative Procedure}
\end{algorithm}
Modern adaptations for the proof of convergence for the Algorithm  \ref{alg:fortet} can be found in \citep{essid2019traversing, chen2016entropic}, however these proofs are very technical and beyond the scope of this survey.  Let us now provide an intuition behind each step in the algorithm :

\begin{itemize}
    \item $\hphi_0^{(i)}(\vx) := \frac{\pi_0(\vx)}{\phi_0^{(i)}(\vx)}$: enforces the marginal/boundary constraint at time $0$. That is it enforces that the product of the factors/potentials match the marginal distribution $\pi_0$ for a given 
    \item $\hphi_1^{(i)}(\vy) := \int  p(\vy | \vx) \hphi_0^{(i)}(\vx) d\vx$ : Now that we have the factors $\phi_0^{(i)}(\vx) \hphi_0^{(i)}(\vx) := {\pi_0(\vx)}$ for the marginal at $t=0$ we transport/transition them to the marginal at time $t=1$ via marginalising the current estimate of the joint posterior $\pi_1(\vy) = \phi_1(\vy) \int p(\vy| \vx) \hphi_0^{(i)}(\vx) d\vx$.
    \item  $\phi_1^{(i)}(\vy) := \frac{\pi_1(\vy)}{\hphi_1^{(i)}(\vy)}$: As with $t=0$ we enforce the marginal/boundary  constraint such that  $\phi_1^{(i)}(\vy) \hphi_1^{(i)}(\vy) := {\pi_1(\vy)}$. 
    \item $\phi^{(i+1)}_0(\vx) := \int  p(\vy | \vx) \phi_1^{(i)}(\vy) d\vy$; Now that we have enforced the constraint for $t=1$ we marginalise our current estimate of the joint to move from $\vy$ to $\vx$ and repeat.
\end{itemize}

Now we can see that Fortet's algorithm is quite intuitive, we initialise the potential at time $t=0$ and what is effectively the prior marginal and iterate the Schrödinger system until reaching a fixed point where the constraints are satisfied by alternating the constraint satisfaction between $t=0$ and $t=1$, the leads us to make the following observation:
\begin{observation}
Fortet's algorithm starting at $t=1$ rather than $t=0$ is equivalent sequentially alternating between solving  Forwards and Backwards static Half Bridges.
\begin{algorithm} \label{alg:ipfp_intro}
\SetKwInOut{Input}{input}
\Input{$\pi_0(\vx), \pi_1(\vy), p(\vy | \vx)$}
Initialise:\\
$p^{\W^{\gamma}}_1(\vy)$ such that $p^{\W^{\gamma}}_1(\vy) <\!< \pi_1(\vy)$ \\
$ p^{*}_{0}(\vx,\vy) =p^{\W^{\gamma}}(\vx,\vy)$\\
$i=0$ \\
    \Repeat{convergence}{
      $i := i + 1$ \\
     $ q^{*}_{i}(\vx,\vy) = \inf_{q(\vx,\vy) \in \calD( \cdot, \pi_1)} \KL  (q(\vx,\vy) || p^{*}_{i-1}(\vx,\vy))$\\ 
     $ p{*}_{i}(\vx,\vy)  = \inf_{p(\vx,\vy) \in \calD(\pi_0, \cdot)} \KL  (p(\vx,\vy) ||  q^{*}_{i}(\vx,\vy))$
    }
\Return{$q^{*}_{i}(\vx,\vy) , p{*}_{i}(\vx,\vy)$}
\caption{Alternating half bridges (\cite{kullback1968probability} IPFP) }
\end{algorithm}
\end{observation}
\begin{proof}
Consider the first two iterations of Algorithm \ref{alg:ipfp_intro}:

Using Theorem \ref{thrm:static_half_backward}  The solution to the Backward half bridge
 \begin{align}
        \inf_{q(\vx,\vy) \in \calD( \cdot, \pi_1)} \KL  &(q(\vx,\vy) || p^{\W^{\gamma}}(\vx,\vy)) \nonumber 
\end{align}
is:
\begin{align}
    q_0^{*} (\vx, \vy) = p^{\W^{\gamma}}_0(\vx) p^{\W^{\gamma}}(\vy| \vx) \frac{\pi_1(\vy)}{p^{\W^{\gamma}}_1(\vy)}
\end{align}
Now we setup the following forward bridge:
\begin{align}
    \arginf_{p_0(\vx, \vy)  \in \calD(\pi_0 , \cdot)}\KL (p_0(\vx, \vy) ||q_0^{*} (\vx, \vy))
\end{align}
which following theorem \ref{eq:static_bridge_forward} can be solved by:
\begingroup
\allowdisplaybreaks
\begin{align}
    p_0^{*} (\vx, \vy) &= q_0^{*} (\vx, \vy) \frac{\pi_0(\vx)}{q_0^{*} (\vx)} \\
 &=  p^{\W^{\gamma}}(\vy| \vx) \frac{\pi_1(\vy)}{p^{\W^{\gamma}}_1(\vy)} \frac{\pi_0(\vx)}{\int   p^{\W^{\gamma}}(\vy| \vx) \frac{\pi_1(\vy)}{p^{\W^{\gamma}}_1(\vy)} d\vy}
\end{align}
\endgroup

If we proceed on to the second iteration of this procedure the  following forward bridge step will yield:
\begin{align}
    q_1^{*} (\vx, \vy) =  p_0^{*} (\vx, \vy) \frac{p^{\W^{\gamma}}_1(\vy)}{ \underbrace{\displaystyle\int \frac{p^{\W^{\gamma}}(\vy| \vx)\pi_0(\vx)}{\int p^{\W^{\gamma}}(\vy| \vx) \frac{\pi_1(\vy)}{p^{\W^{\gamma}}_1(\vy)} d\vy}d\vx}_{{\phi}^{1}(\vy)}} 
\end{align}
and backward step:
\begin{align}
    p_1{*} (\vx, \vy) &= q_1^{*} (\vx, \vy) \frac{\int    p^{\W^{\gamma}}(\vy| \vx) \frac{\pi_1(\vy)}{p^{\W^{\gamma}}_1(\vy)}  d \vy}{\int    p^{\W^{\gamma}}(\vy| \vx) \frac{\pi_1(\vy)}{{\phi}^{1}(\vy)}  d \vy}
\end{align}
re-labeling: 
\begin{align}
    \phi^0(\vy)&=p^{\W^{\gamma}}_1(\vy) \\ 
    \hat{\phi}_0^{i}(\vx) &= \int  p^{\W^{\gamma}}(\vy| \vx) \frac{\pi_1(\vy)}{{\phi}^{i}(\vy)}  d \vy
\end{align}
we can make an inductive argument on $i$ for the following inductive hypothesis \footnote{Some simple term cancellation steps have been omitted to reduce verbosity.}:
\begin{align} \label{eq:recurrence}
  {\phi}^{i+1}(\vy) =  \displaystyle\int \frac{p^{\W^{\gamma}}(\vy| \vx)\pi_0(\vx)}{\int p^{\W^{\gamma}}(\vy| \vx) \frac{\pi_1(\vy)}{\phi^i(\vy)} d\vy}d\vx
 \end{align}
 \begin{align}
  q_i^{*} (\vx, \vy) =   p_{i-1}^{*} (\vx, \vy) \frac{\phi^{i-1}(\vy)}{{\phi}^{i}(\vy)} 
\end{align}
 \begin{align}
      p_i{*} (\vx, \vy) =     q_i^{*} (\vx, \vy) \frac{\hat{\phi}_0^{i-1}(\vx)}{\hat{\phi}_0^{i}(\vx)} 
\end{align}
We can see that the  recurrence in Equation \ref{eq:recurrence} is the exact same set of steps performed by Fortet's algorithm if we were to reverse the time order or start Fortet's algorithm at step 5 and consider the first steps  as an initialisation of $\phi_0(\vy)$.
\end{proof}

Whilst in hindsight the above observation may seem simple we regard it as a contribution nonetheless as we have not observed a formal argument made towards that connection. As we will see in the following sections this connections bridges the stream of iterative proportional fitting algorithms with Fortet's algorithm.

\section{Kullback's IPFP}
The original Iterative Proportional Fitting Procedure (IPFP) consists en estimating a normalised contingency table (discrete joint distribution) given prescribed marginals, via some form of information discrimination/maximum entropy principle. Our interest however is in the continuous variant of IPFP which dates back to Kullback \citep{kullback1968probability}.

What we call in this section Kullback's IPFP is in fact Algorithm \ref{alg:ipfp_intro} which we have introduced via its formal connection to Fortet's algorithm.  The first complete proof for convergence to the  Schrödinger bridge Algorithm \ref{alg:ipfp_intro} was provided in \cite{ruschendorf1995convergence} using information geometric arguments from \cite{csiszar1975divergence}.


\section{Generalised IPFP}

We call Generalised Iterative Proportional Fitting Procedure (g-IPFP) the extension of the continuous IPFP initialise proposed by Kullback to a more setting over path measures as presented in \cite{cramer2000probability, bernton2019schr}. The method is identical to the regular IPFP only that it re-states the problem in terms of probability measures:
\begin{algorithm} \label{alg:gipfp}
\SetKwInOut{Input}{input}
\Input{$\pi_0(\vx), \pi_1(\vy), \W^{\gamma}$}
Initialise:\\
$\P^{*}_0 =\W^{\gamma}$\\
$i=0$ \\
    \Repeat{convergence}{
      $i := i + 1$ \\
     $ \Q_i^{*} = \inf_{\Q \in \calD( \cdot, \pi_1)} \KL  (\Q|| \P^{*}_{i-1})$\\ 
     $ \P_i^{*}  = \inf_{\P \in \calD(\pi_0, \cdot)} \KL  (\P||  \Q^{*}_{i})$
    }
\Return{$\Q_i^{*}, \P_i^{*}$}
\caption{g-IPFP \citep{cramer2000probability} }
\end{algorithm}

Then by Theorems \ref{thrm:half_bridge_forward},\ref{thrm:half_bridge_backward} steps 6 and 7 of Algorithm \ref{alg:gipfp} can be expressed in closed form in terms of known quantities:
\begin{align}
    {\Q}^{*}_i\left( A_{[0,1)} \times A_1\right) =  \int_{ A_{[0,1)} \times A_1}  \frac{d \pi_1}{ d p_0^\W} d\P^{*}_{i-1}
\end{align}
\begin{align}
    {\P}^{*}_i\left(A_0 \times A_{(0,1]}\right) =  \int_{A_0\times A_{(0,1]}} \frac{d \pi_0}{ dp_0^\W} d\Q^{*}_i
\end{align}
An important thing to note about the above solutions is that while these quantities are written in terms of components that we "know" such components are themselves not available in closed form and require some form of approximation scheme in order to be computed.

Again note that via the disintegration theorem we can reduce g-IPFP to the standard IPFP by noting that $\Q^*_i(\cdot |\vx,\vy) =\P^*_i(\cdot |\vx,\vy) = \W(\cdot |\vx,\vy)$ remains invariant across iterations, thus we highligt that more than an algorithm g-IPFP is an algorithmic framework for the development and design of algorithms aimed at solving the Schrödinger Bridge.
% \subsection{Formal Connection to Fortet's Algorithm}
The proof from \cite{ruschendorf1995convergence} extends naturally to g-IPFP as mentioned in \cite{bernton2019schr}, furthermore \cite{bernton2019schr} provide additional results regarding the covnergence rate of g-IPFP.
\begin{figure}[h!]
    \centering
    \includegraphics[width=\linewidth]{images/IPFP_Geanology.png}
    \caption{Genealogy of IPFP based algorithms for solving the Schrödinger. ? Symbolises an area open for development. Diagram could be more fine-grained in terms of the approach i.e. whether it is the control formulation of the problem. }
    \label{fig:my_label}
\end{figure}

%\chapter{Related Work} 
\chapter{Related Problems}
\section{Continuous Time Flows}

Imagine as probabilistic modeller if you were given the problem of mapping from one distribution to another. One of the simplest ways of going about such task is to specify a generative process of the form:
\begin{align*}
    \rvx &\sim \pi_0 \\
    \rvy &= \calT_{\theta}(\rvx)
\end{align*}
And then maximise the marginal likelihood for a set of observations $\{\vy_i \sim \pi_1 \}$:
\begin{align*}
    \prod_i p(\vy_i) = \prod_i \int p_{\theta}(\vy_i | \vx) d\pi_0(\vx)
\end{align*}

\section{Domain Adaptation and Generative Adversarial Networks (GANs)}

\subsection{Short Introduction to Domain Adaptation via GANs}

To recap what a GAN looks like in our notation its the following two steps:
 Estimating the surrogate to later be fitted by model $p_{\theta}(y)$:
 $$ \hat{\phi} = \argmin_{\phi} \alpha \E_{\pi_1(y)}[-\log D_{\phi}(y)] + (1-\alpha)\E_{p_{\theta}(y)}[-\log (1-D_{\phi}(y))]$$ 
 * Fitting model $p_{\theta}(y)$ on the estimated surrogate:
 $$ -\E_{p_{\theta}(y)}\left[\log(D_{\hat{\phi}}(y))\right] $$ 

The generator step in practice for GANs \citep{goodfellow2014generative} typically minimises $-\E_{p_{\theta}(\vy)}\left[\log(D(\vy))\right]$  , following \cite{goodfellow2014generative} this is equivalent to maximising  $\E_{p_{\theta}(\vy)}\left[\log(1-D(\vy))\right]$.


\subsection{Connection To IPFP}
Starting from the static formulation of the problem
\begin{align*}
\argmin_{q(\vx,\vy) \in \mathcal{D}(\pi_0, \pi_1)}- \int q(\vx,\vy) \log p^{\W^{\gamma}}(\vx ,\vy )d\vx d\vy +\int q(\vx,\vy) \log q(\vx ,\vy )d\vx d\vy
\end{align*}
Now let us consider the backwards step in IPFP for the $i$-th iteration:
\begin{align*}
\arginf_{q(\vx,\vy)  \in \mathcal{D}(\pi_1)}- \int q(\vx,\vy)  \log p^{i-1}(\vx,\vy)d\vx d\vy +\int  q(\vx,\vy) \log  q(\vx,\vy) d\vx d\vy
\end{align*}
we can enforce this constraint using the product rule i.e. $q(\vx,\vy) = q_{\phi}(\vx|\vy) \pi_1(\vy)$ (we can parametrise $q_{\phi}(\vx|\vy)$ with a powerful estimator):
\begin{align*}
\argmin_{\phi}&\!\!-\!\!\int\!\!q_{\phi}(\vx|\vy) \pi_1(\vy) \log p^{i-1}(\vx,\vy)d\vx d\vy\!+\!\!\!\int\!\!q_{\phi}(\vx|\vy) \pi_1(\vy) \log q_{\phi}(\vx|\vy)
\pi_1(y)d\vx d\vy\\
\argmin_{\phi}&- \int q_{\phi}(\vx|\vy) \pi_1(\vy) \log p^{i-1}(\vx,\vy)d\vx d\vy +\int q_{\phi}(\vx|\vy)\pi_1(\vy) \log q_{\phi}(\vx|\vy)
d\vx d\vy
\end{align*}
Now following our selected parametrisation if we are beyond the first iteration the product rule yields $p^{i-1}(\vx , \vy)= p^{i-1}_{\theta}(\vy|\vx)\pi_0(\vx)$
\begin{align*}
\argmin_\theta&- \int q_{\phi}(\vx|\vy) \pi_1(\vy) \log  p^{i-1}_{\theta}(\vx|\vy)dxdy - \int q_{\phi}(\vx|\vy) \pi_1(\vy) \log  \pi_0(\vx) d\vx d\vy \\
&+\int q_{\phi}(\vx|\vx) \pi_1(\vy) \log q_{\phi]}(\vx|\vy)d\vx d\vy 
\end{align*}
Simplifying furhter:
\begin{align*}
\argmin_\phi- \E_{q_{\phi}(\vx|\vy)\pi_1(\vy)}\left[  \log  p^{i-1}_{\theta}(\vy|\vx)\right] -  \E_{q_{\phi}(\vx)}\left[ \log  \pi_0(\vx) \right] - H\left(q_{\phi}(\vx|\vy)\pi_1(\vy)\right)
\end{align*}

Sampling from $q_{\phi}(\vy|\vx)\pi_1(y)$ can be achieved via  ancestral sampling and we can parametrise $q_{\phi}(\vy|\vx)=\mathcal{N}(\vx | \mu_{\phi}(\vy), \sigma^2_\phi(\vy))$ following \cite{kingma2013auto} such that it is easy to sample conditioned on $\vy$. Under the discussed parametrisations expectations are taken with respect to the empirical distribution via ancestral sampling and thus we don't require any importance sampling or the likes, however we have introduced some bias by parametrising $q_{\phi}(\vy|\vx)$ with a class of distributions.

What is more interesting is that the above objectives is very similar to the cycle-GAN \citep{zhu2017unpaired} objective which gives us a nice link to a wide variety of successful empirical methods:

Backwards step:
\begin{align*}
\argmin_\phi- \E_{q_{\phi}(\vy|\vx)\pi_1(\vy)}\left[  \log  p^{i-1}_{\theta}(\vy|\vx)\right] -  \E_{q_{\phi}(\vx)}\left[ \log  \pi_0(\vx) \right] - H\left(q_{\phi}(\vy|\vx)\pi_1(\vy)\right)
\end{align*}
Forwards step:
\begin{align*}
\argmin_\theta- \E_{p_{\theta}(\vy|\vx)\pi_0(\vx)}\left[  \log  q^i_{\phi}(\vy|\vx)\right] -  \E_{p_{\theta}(\vy)}\left[ \log  \pi_1(\vy) \right] - H\left(p_{\theta}(\vy|\vx)\pi_0(\vx)\right)
\end{align*}

\begin{observation}\label{obs:cycle}
Using our proposed parametrisation we can see that the term:
$$\E_{p^i_{\theta}(\vy|\vx)\pi_0(\vx)}\left[  \log  q^i_{\phi}(\vy|\vx)\right] \propto \E_{\pi_0(\vx)\mathcal{N}(\epsilon|\textbf{0},\I )}\left[  -  \frac{1}{2\sigma_x^2}\Big|\Big|\vx- \mu_\phi\left(\mu_\theta(\vx) + \sigma_y \bm{\epsilon}\right) \Big|\Big|^2\right],$$
matches the corresponding the cycle-consistency loss terms in cycle GAN \cite{zhu2017unpaired} in the $\sigma_y \downarrow 0$ limit.
\end{observation}
\begin{proof}
For simplicily lets make the variance function independent of the input $\sigma^2_{\theta}(\vx) = \sigma_{x}^2 \I$ 
\begin{align*}
\E_{p_{\theta}(\vy|\vx)\pi_0(\vx)}\left[  \log  q^i_{\phi}{\phi}(\vy|\vx)\right] \propto \E_{p_{\theta}(\vy|\vx)\pi_0(\vx)}\left[  -  \frac{1}{2\sigma_x^2}||\vx- {\mu}_{\phi}(\vy))||^2\right]
\end{align*}
We can apply the reparametrisation trick \cite{kingma2013auto} to $p_{\theta}(\vy|\vx)\pi_0(\vx)$ : 
\begin{align*}
    \vx &\sim \pi_0(\vx) \\
    \vy &= {\mu}_{\theta}(\vx) + \sigma_y \bm{\epsilon} \quad \bm{\epsilon} \sim \mathcal{N}(\textbf{0}, \I)
\end{align*}

Using the above reparametrisation we can re-write the cross-term loss as : 

\begin{align*}
 \E_{p_{\theta}(\vy|\vx)\pi_0(\vx)}\left[  \log  q^i_{\phi}{\phi}(\vy|\vx)\right] \propto \E_{\pi_0(\vx)\mathcal{N}(\epsilon|\textbf{0},\I )}\left[  -  \frac{1}{2\sigma_x^2}\Big|\Big|\vx- \mu_\phi\left(\mu_\theta(\vx) + \sigma_y \bm{\epsilon}\right) \Big|\Big|^2\right]
\end{align*}

Where $ -  \frac{1}{2\sigma_x^2}\Big|\Big|\vx- \mu_\phi\left(\mu_\theta(\vx) + \sigma_y \bm{\epsilon}\right) \Big|\Big|^22$ takes the same autoencoder(AE) form as the cycle consistency loss in cycle GAN with some added noise (they are related asymptotically in the zero noise limit just like VAEs and AEs).
\end{proof}

For notational simplicity we have treated the the $\sigma_i$ terms as constants in the above derivations, adapting the above argument to their non-constant counterparts is simple and does not add much to Observation \ref{obs:cycle}.


 Now we will focus on the connection between our remaining terms and the generative loss:

\begin{observation}
Up to optimisation constants and for the optimal discriminator $D^{*}$ and a generator $p_{\theta}(\vy | \vx)$ as defined in \citep{goodfellow2014generative,mohamed2016learning}, we have the following:
\begin{align*}
-\E_{p_{\theta}(\vy)}\left[ \log  \pi_1(\vy) \right] \propto-\E_{p_{\theta}(\vy)}\left[\log(D^{*}(\vy))\right] - \E_{p_{\theta}(\vy)}\left[\log\left(p_{\theta}(\vy) + \pi_1(\vy)\right)\right],
\end{align*}
In short we can express cross entropy between our model and the empirical distribution in terms of of the optimal discriminator $D^{*}$ and a further term (which is one of the terms in the Jensen Shannon Divergence - JSD ). 
\end{observation}
\begin{proof}

Using the ratio expression from \cite{mohamed2016learning}
\begin{align*}
\log D^{*}(\vy) &= \log\left(\frac{\pi_1(\vy)p(c=1)}{p(\vy)}\right) \\
&=\log\left(\frac{\pi_1(\vy)p(c=1)}{p(c=1)p(y|c=1) + p(c=0)p(\vy|c=0)}\right) \\
&= \log\left(\frac{\pi_1(\vy)\alpha}{\alpha\pi_1(\vy) + (1-\alpha)  p_{\theta}(\vy)}\right) \\
&\propto \log\left(\pi_1(\vy)\right) - \log\left(\alpha\pi_1(\vy)  + (1-\alpha)p_{\theta}(\vy) \right)
\end{align*}

Considering the case for $\alpha=\frac{1}{2}$ we have : 
\begin{align*}
\log D^{*}(\vy) \propto \log\left(\pi_1(\vy)\right) - \log\left(p_{\theta}(\vy) + \pi_1(\vy)\right)
\end{align*}

thus:
\begin{align}\label{eq:gan_entropy}
\E_{p_{\theta}(\vy)}\left[\log D^{*}(\vy)\right] \propto \E_{p_{\theta}(\vy)}\left[\log\left(\pi_1(\vy)\right)\right] -\E_{p_{\theta}(\vy)}\left[\log\left(p_{\theta}(\vy) + \pi_1(\vy)\right)\right]
\end{align}

\end{proof}

This holds for an optimal classifier $D$ that can tell apart samples from $\pi_\theta(y)$ and $\pi_1(y)$ see [shakir density ratio](http://blog.shakirm.com/2018/01/machine-learning-trick-of-the-day-7-density-ratio-trick/) for proof/motivation (for more details  in context of GANs see [here](https://arxiv.org/pdf/1610.03483.pdf)), the main differences we have in our method is the aditional entropy term which helps with making our estimates spread out, whilst GANs instead have this half JS term.  So effectively we have two GANs going forwards and backwards in turn.

Lets quickly zoom into the terms that differ between our loss and the GAN loss removing constants the terms are:


\begin{align}
 \E_{p_{\theta}(y|x)\pi_0(x)}\left[ \log p_{\theta}(y|x) \right]\quad &\text{vs} \quad  \E_{p_{\theta}(y)}\left[\log\left(p_{\theta}(y) + \pi_1(y)\right)\right]
\end{align}

The term $H_{\theta}(y|x) =\E_{p_{\theta}(y|x)\pi_0(x)}\left[ \log p_{\theta}(y|x) \right]$ is a conditoinal entropy whilst the term $\E_{p_{\theta}(y)}\left[\log\left(p_{\theta}(y) + \pi_1(y)\right)\right]$ is one of the terms in the Jensen Shanon divergence, both prevent the delta collapse of the reverse cross entropy, and is the main difference between GANs and a single forward (or backwards) pass of IPF on the schrodinger bridge problem.

 Note than under this parametrisation the term $H_{\theta}(y|x)$ can be obtained in closed form $\E_{\pi_1(y)}[\log \text{NN}_{\sigma}(y)]$ and has the clear interpretation in that it maximises variance / spread of our mapping.




%\chapter{Design and Implementation}
\chapter{Empirical Schrodinger Bridges}
\section{Stochastic Control Approach}
\subsection{Forwards and Backwards Diffusion's}
\section{Maximum Likelihood Approach \citep{pavon2018data}}
\subsection{MLE-IPFP is not Coordinate Ascent}
\subsection{Non-parametric Approach}
\subsection{Importance Sampling Approach by \citet{pavon2018data} }
\subsection{Analysis of simple Gaussian Parametrisation}
\subsection{Mixture of Exponentiated Quadratics}

\subsection{Noise Contrastive Estimation}
\section{Comparison of Approaches}

%\chapter{Evaluation} 
\chapter{Experiments}

%\chapter{Summary and Conclusions} 
\chapter{Discussion}


\appendix
\singlespacing

\bibliographystyle{icml} 
\bibliography{bibliography} 

\end{document}
